{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (0.2.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (4.46.3)\n",
      "Requirement already satisfied: datasets in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (3.2.0)\n",
      "Requirement already satisfied: torch in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (2.5.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (1.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (3.16.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (from datasets) (18.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.2.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (from datasets) (3.10.10)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (from torch) (70.0.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->datasets) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->datasets) (1.17.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (from requests->transformers) (2024.6.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\program files\\python312\\lib\\site-packages\\vboxapi-1.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nepalitokenizers in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (0.0.2)\n",
      "Requirement already satisfied: tokenizers>=0.13.3 in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (from nepalitokenizers) (0.20.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (from tokenizers>=0.13.3->nepalitokenizers) (0.26.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.3->nepalitokenizers) (3.16.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.3->nepalitokenizers) (2024.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.3->nepalitokenizers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.3->nepalitokenizers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.3->nepalitokenizers) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.3->nepalitokenizers) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.3->nepalitokenizers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.42.1->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.3->nepalitokenizers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.3->nepalitokenizers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.3->nepalitokenizers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.3->nepalitokenizers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\l e g i o n\\appdata\\roaming\\python\\python312\\site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.3->nepalitokenizers) (2024.6.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\program files\\python312\\lib\\site-packages\\vboxapi-1.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\n"
     ]
    }
   ],
   "source": [
    "%pip install sentencepiece transformers datasets torch scikit-learn\n",
    "%pip install nepalitokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\L E G I O N\\AppData\\Roaming\\Python\\Python312\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sentencepiece as spm\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Train SentencePiece Tokenizer\n",
    "def train_sentencepiece_tokenizer(data_file, model_prefix, vocab_size=32000):\n",
    "    \"\"\"\n",
    "    Train a SentencePiece tokenizer for the Nepali language.\n",
    "    \"\"\"\n",
    "    spm.SentencePieceTrainer.train(\n",
    "        input=data_file,\n",
    "        model_prefix=model_prefix,\n",
    "        vocab_size=vocab_size,\n",
    "        model_type=\"bpe\",  # Can be \"unigram\", \"bpe\", etc.\n",
    "        character_coverage=0.9995,  # Adjust for Devanagari\n",
    "        pad_id=0,\n",
    "        unk_id=1,\n",
    "        bos_id=2,\n",
    "        eos_id=3\n",
    "    )\n",
    "    print(f\"SentencePiece model trained and saved as {model_prefix}.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "\n",
    "input_file = 'chunkeddataset.txt'\n",
    "train_file = 'nepali_train.csv'\n",
    "test_file = 'nepali_test.csv'\n",
    "test_size_ratio = 0.2  # 20% for testing\n",
    "\n",
    "# Process the text file and split into train/test datasets\n",
    "with open(input_file, 'r', encoding='utf-8') as infile, \\\n",
    "     open(train_file, 'w', encoding='utf-8', newline='') as train_out, \\\n",
    "     open(test_file, 'w', encoding='utf-8', newline='') as test_out:\n",
    "    \n",
    "    train_writer = csv.writer(train_out)\n",
    "    test_writer = csv.writer(test_out)\n",
    "    \n",
    "    # Write headers\n",
    "    train_writer.writerow(['text'])\n",
    "    test_writer.writerow(['text'])\n",
    "    \n",
    "    # Read and process line by line\n",
    "    for line in infile:\n",
    "        line = line.strip()\n",
    "        if line:  # Skip empty lines\n",
    "            if random.random() < test_size_ratio:\n",
    "                test_writer.writerow([line])\n",
    "            else:\n",
    "                train_writer.writerow([line])\n",
    "\n",
    "\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned and overwritten nepali_train.csv\n"
     ]
    }
   ],
   "source": [
    "file_path = 'nepali_train.csv'\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    rows = list(csv.reader(file))\n",
    "\n",
    "# Filter out rows containing '------'\n",
    "rows = [row for row in rows if '------' not in row]\n",
    "\n",
    "# Overwrite the original file with cleaned data\n",
    "with open(file_path, 'w', encoding='utf-8', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(rows)\n",
    "\n",
    "print(f\"Cleaned and overwritten {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned and overwritten nepali_test.csv\n"
     ]
    }
   ],
   "source": [
    "file_path = 'nepali_test.csv'\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    rows = list(csv.reader(file))\n",
    "\n",
    "# Filter out rows containing '------'\n",
    "rows = [row for row in rows if '------' not in row]\n",
    "\n",
    "# Overwrite the original file with cleaned data\n",
    "with open(file_path, 'w', encoding='utf-8', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(rows)\n",
    "\n",
    "print(f\"Cleaned and overwritten {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load Dataset\n",
    "def load_nepali_dataset():\n",
    "    \"\"\"\n",
    "    Load or create a Nepali dataset for the classification task.\n",
    "    \"\"\"\n",
    "    # Replace this with actual data loading logic\n",
    "    dataset = load_dataset(\"csv\", data_files={\"train\": \"nepali_train.csv\", \"test\": \"nepali_test.csv\"})\n",
    "    return DatasetDict({\"train\": dataset[\"train\"], \"test\": dataset[\"test\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from nepalitokenizers import WordPiece, SentencePiece\n",
    "from datasets import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize tokenizers\n",
    "tokenizer_wp = WordPiece()\n",
    "tokenizer_sp = SentencePiece()\n",
    "file_path='chunkeddataset.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to load Nepali text from a .txt file\n",
    "def load_nepali_text_file(file_path):\n",
    "    \"\"\"\n",
    "    Load Nepali text from a .txt file and return a list of sentences.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        # Read all lines from the file\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    # Clean up the lines: Remove any unnecessary newlines and empty lines\n",
    "    sentences = [line.strip() for line in lines if line.strip()]\n",
    "    return sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to tokenize a dataset using a specified tokenizer\n",
    "# Function to tokenize a dataset using a specified tokenizer\n",
    "def tokenize_dataset(sentences, tokenizer):\n",
    "    \"\"\"\n",
    "    Tokenizes each Nepali sentence using the specified tokenizer.\n",
    "    \"\"\"\n",
    "    def tokenize_fn(text):\n",
    "        # Tokenizing the text using the provided tokenizer\n",
    "        tokens = tokenizer.encode(text)\n",
    "        return {\n",
    "            \"ids\": tokens.ids,\n",
    "            \"tokens\": tokens.tokens\n",
    "        }\n",
    "\n",
    "    # Tokenize each sentence and collect input_ids and tokens\n",
    "    tokenized_data = [tokenize_fn(sentence) for sentence in sentences]\n",
    "\n",
    "    # Separate ids and tokens into their respective lists\n",
    "    input_ids = [item['ids'] for item in tokenized_data]\n",
    "    tokens = [item['tokens'] for item in tokenized_data]\n",
    "\n",
    "    return input_ids, tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to save tokenized data as .pkl\n",
    "def save_as_pkl(data, file_name):\n",
    "    with open(file_name, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "# Function to save vocabulary as .vocab\n",
    "def save_vocab(vocab, file_name):\n",
    "    with open(file_name, 'w', encoding='utf-8') as f:\n",
    "        for token in vocab:\n",
    "            f.write(f\"{token}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized data and vocab files saved successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load Nepali text from a .txt file\n",
    "sentences = load_nepali_text_file(file_path)\n",
    "\n",
    "# Tokenize the dataset using SentencePiece\n",
    "input_ids_sp, tokens_sp = tokenize_dataset(sentences, tokenizer_sp)\n",
    "\n",
    "# Save tokenized data as .pkl\n",
    "save_as_pkl({\n",
    "    \"input_ids\": input_ids_sp,\n",
    "    \"tokens\": tokens_sp\n",
    "}, \"sentencepiece_tokenized.pkl\")\n",
    "\n",
    "# Save SentencePiece vocabulary\n",
    "sp_vocab = tokenizer_sp.get_vocab()  # Assuming get_vocab returns a list of vocabulary tokens\n",
    "save_vocab(sp_vocab, \"sentencepiece_vocab.vocab\")\n",
    "\n",
    "# Tokenize the dataset using WordPiece\n",
    "input_ids_wp, tokens_wp = tokenize_dataset(sentences, tokenizer_wp)\n",
    "\n",
    "# Save tokenized data as .pkl\n",
    "save_as_pkl({\n",
    "    \"input_ids\": input_ids_wp,\n",
    "    \"tokens\": tokens_wp\n",
    "}, \"wordpiece_tokenized.pkl\")\n",
    "\n",
    "# Save WordPiece vocabulary\n",
    "wp_vocab = tokenizer_wp.get_vocab()  # Assuming get_vocab returns a list of vocabulary tokens\n",
    "save_vocab(wp_vocab, \"wordpiece_vocab.vocab\")\n",
    "\n",
    "# Optionally, display a confirmation message\n",
    "print(\"Tokenized data and vocab files saved successfully.\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentencePiece Tokenized IDs: [[35, 43, 1721, 14113, 9, 215, 2332, 7, 3591, 13277, 12, 3218, 25, 8962, 8652, 2894, 1028, 9169, 13, 7352, 1298, 1771, 111, 16441, 336, 135, 7, 24020, 8425, 2528, 687, 2189, 8425, 2014, 6789, 349, 9853, 768, 1771, 858, 1548, 2622, 26, 2216, 8425, 10, 1791, 43, 7690, 11002, 8992, 797, 10639, 8425, 2332, 36, 402, 203, 20938, 21659, 14713, 10, 44, 6870, 402, 1, 0], [7, 199, 2014, 6789, 349, 9853, 768, 1771, 858, 1548, 2622, 26, 2216, 8425, 10, 1791, 43, 7690, 11002, 8992, 797, 10639, 8425, 2332, 36, 402, 203, 20938, 21659, 14713, 10, 44, 6870, 402, 1, 0], [7, 199, 2014, 6789, 349, 9853, 768, 1771, 858, 1548, 2622, 26, 2216, 8425, 10, 1791, 43, 7690, 11002, 8992, 797, 10639, 8425, 2332, 36, 402, 203, 20938, 21659, 14713, 10, 44, 6870, 402, 119, 7690, 11002, 1881, 145, 349, 1869, 3758, 9, 2121, 22, 46, 31, 402, 203, 14810, 3758, 4799, 367, 130, 47, 7, 24020, 8425, 10, 13, 1, 0], [119, 7690, 11002, 1881, 145, 349, 1869, 3758, 9, 2121, 22, 46, 31, 402, 203, 14810, 3758, 4799, 367, 130, 47, 7, 24020, 8425, 10, 13, 1, 0], [119, 7690, 11002, 1881, 145, 349, 1869, 3758, 9, 2121, 22, 46, 31, 402, 203, 14810, 3758, 4799, 367, 130, 47, 7, 24020, 8425, 10, 13, 3995, 285, 20471, 111, 895, 2098, 664, 285, 5859, 26, 20471, 26, 2005, 285, 4889, 3631, 33, 20471, 12048, 5284, 35, 5658, 476, 125, 203, 44, 8425, 1648, 1869, 32, 13423, 1, 0]]\n",
      "SentencePiece Tokens: [['▁यो', '▁एक', '▁स्वतन्त्र', 'विश्व', 'को', 'श', 'हो', '▁', 'जसलाई', 'सबै', 'ले', '▁सम्पादन', '▁गर्न', '▁सक्छन्।', 'नेपाली', '▁भाषामा', '▁कुल', '३१', ',', '३५', '०', '▁लेख', 'हरू', 'सङ्ग्रह', 'ित', '▁छन्।', '▁', 'देवनागरी', '▁लिपि', 'अथवा', 'ना', 'गरी', '▁लिपि', 'बा', 'याँ', '▁देखि', '▁दायाँ', '▁सम्म', '▁लेख', 'िने', 'अ', 'क्ष', 'र', 'ात्मक', '▁लिपि', 'मा', '▁आधारित', '▁एक', 'प्रा', 'चीन', '▁ब्रा', 'ह', '्मी', '▁लिपि', 'हो', '।', '▁यसको', '▁प्रयोग', 'भारतीय', '▁उपमहा', 'द्वीप', 'मा', '▁हुने', '▁गर्दछ।', '▁यसको', '<sep>', '<cls>'], ['▁', 'ि', 'बा', 'याँ', '▁देखि', '▁दायाँ', '▁सम्म', '▁लेख', 'िने', 'अ', 'क्ष', 'र', 'ात्मक', '▁लिपि', 'मा', '▁आधारित', '▁एक', 'प्रा', 'चीन', '▁ब्रा', 'ह', '्मी', '▁लिपि', 'हो', '।', '▁यसको', '▁प्रयोग', 'भारतीय', '▁उपमहा', 'द्वीप', 'मा', '▁हुने', '▁गर्दछ।', '▁यसको', '<sep>', '<cls>'], ['▁', 'ि', 'बा', 'याँ', '▁देखि', '▁दायाँ', '▁सम्म', '▁लेख', 'िने', 'अ', 'क्ष', 'र', 'ात्मक', '▁लिपि', 'मा', '▁आधारित', '▁एक', 'प्रा', 'चीन', '▁ब्रा', 'ह', '्मी', '▁लिपि', 'हो', '।', '▁यसको', '▁प्रयोग', 'भारतीय', '▁उपमहा', 'द्वीप', 'मा', '▁हुने', '▁गर्दछ।', '▁यसको', '▁विकास', 'प्रा', 'चीन', '▁भारतमा', '▁पहिलो', '▁देखि', '▁चौथो', '▁शताब्दी', 'को', '▁बीचमा', '▁भएको', '▁थियो', '▁भने', '▁यसको', '▁प्रयोग', '▁सातौँ', '▁शताब्दी', '▁देखी', '▁हुँदै', '▁आएको', '▁छ।', '▁', 'देवनागरी', '▁लिपि', 'मा', ',', '<sep>', '<cls>'], ['▁विकास', 'प्रा', 'चीन', '▁भारतमा', '▁पहिलो', '▁देखि', '▁चौथो', '▁शताब्दी', 'को', '▁बीचमा', '▁भएको', '▁थियो', '▁भने', '▁यसको', '▁प्रयोग', '▁सातौँ', '▁शताब्दी', '▁देखी', '▁हुँदै', '▁आएको', '▁छ।', '▁', 'देवनागरी', '▁लिपि', 'मा', ',', '<sep>', '<cls>'], ['▁विकास', 'प्रा', 'चीन', '▁भारतमा', '▁पहिलो', '▁देखि', '▁चौथो', '▁शताब्दी', 'को', '▁बीचमा', '▁भएको', '▁थियो', '▁भने', '▁यसको', '▁प्रयोग', '▁सातौँ', '▁शताब्दी', '▁देखी', '▁हुँदै', '▁आएको', '▁छ।', '▁', 'देवनागरी', '▁लिपि', 'मा', ',', '▁४७', '▁वटा', 'वर्ण', 'हरू', '▁हुन्छन्', '▁जसमा', '▁१४', '▁वटा', 'स्व', 'र', 'वर्ण', 'र', '▁३३', '▁वटा', 'व्य', 'ञ्ज', 'न', 'वर्ण', 'हुन्छ', 'न्।', '▁यो', '▁संसारमा', '▁सबैभन्दा', '▁बढी', '▁प्रयोग', '▁हुने', '▁लिपि', '▁मध्ये', '▁चौथो', '▁हो', '▁जहा', '<sep>', '<cls>']]\n",
      "WordPiece Tokenized IDs: [[1, 8452, 8472, 10744, 8445, 10488, 8334, 5748, 9313, 13033, 5713, 15959, 8340, 14427, 8444, 11867, 1496, 8691, 13459, 10683, 5792, 5796, 16, 11341, 5723, 8892, 8429, 13816, 9802, 8371, 8425, 1496, 10072, 25694, 5712, 20967, 5757, 5763, 10478, 15925, 5712, 20967, 8392, 8585, 9267, 17488, 9279, 8892, 8492, 5757, 11339, 19392, 20967, 8337, 12152, 8472, 13896, 15893, 21336, 9148, 20967, 9313, 1496, 9640, 9074, 12487, 11450, 28511, 28072, 11098, 8511, 11322, 1496, 9640, 2], [1, 1464, 8392, 8585, 9267, 17488, 9279, 8892, 8492, 5757, 11339, 19392, 20967, 8337, 12152, 8472, 13896, 15893, 21336, 9148, 20967, 9313, 1496, 9640, 9074, 12487, 11450, 28511, 28072, 11098, 8511, 11322, 1496, 9640, 2], [1, 1464, 8392, 8585, 9267, 17488, 9279, 8892, 8492, 5757, 11339, 19392, 20967, 8337, 12152, 8472, 13896, 15893, 21336, 9148, 20967, 9313, 1496, 9640, 9074, 12487, 11450, 28511, 28072, 11098, 8511, 11322, 1496, 9640, 8781, 13896, 15893, 12104, 8904, 9267, 12241, 23826, 12536, 8428, 8491, 8417, 9640, 9074, 27424, 18539, 16007, 9453, 8950, 1430, 1496, 10072, 25694, 5712, 20967, 8337, 16, 2], [1, 8781, 13896, 15893, 12104, 8904, 9267, 12241, 23826, 12536, 8428, 8491, 8417, 9640, 9074, 27424, 18539, 16007, 9453, 8950, 1430, 1496, 10072, 25694, 5712, 20967, 8337, 16, 2], [1, 8781, 13896, 15893, 12104, 8904, 9267, 12241, 23826, 12536, 8428, 8491, 8417, 9640, 9074, 27424, 18539, 16007, 9453, 8950, 1430, 1496, 10072, 25694, 5712, 20967, 8337, 16, 14296, 9421, 10125, 5691, 5698, 8429, 10308, 12444, 9976, 9421, 14120, 10125, 5691, 5698, 5694, 12088, 9421, 9623, 14233, 10125, 5691, 5698, 10204, 8338, 1496, 8452, 16663, 9884, 8979, 9074, 8511, 20967, 11950, 12241, 8406, 1431, 8481, 2]]\n",
      "WordPiece Tokens: [['[CLS]', 'यो', 'एक', 'स्वतन्त्र', '##वि', '##श्व', '##को', '##श', '##हो', 'जसलाई', '##स', '##बै', '##ले', 'सम्पादन', 'गर्न', 'सक्छन्', '।', 'नेपाली', 'भाषामा', 'कुल', '##३', '##१', ',', '३५', '##०', 'लेख', '##हरू', '##सङ्', '##ग्रह', '##ित', 'छन्', '।', 'देव', '##नागर', '##ी', 'लिपि', '##अ', '##थ', '##वान', '##ागर', '##ी', 'लिपि', '##बा', '##याँ', 'देखि', 'दायाँ', 'सम्म', 'लेख', '##िने', '##अ', '##क्षर', '##ात्मक', 'लिपि', '##मा', 'आधारित', 'एक', '##प्रा', '##चीन', 'ब्राह्', '##मी', 'लिपि', '##हो', '।', 'यसको', 'प्रयोग', '##भार', '##तीय', 'उपमहा', '##द्वी', '##पमा', 'हुने', 'गर्दछ', '।', 'यसको', '[SEP]'], ['[CLS]', 'ि', '##बा', '##याँ', 'देखि', 'दायाँ', 'सम्म', 'लेख', '##िने', '##अ', '##क्षर', '##ात्मक', 'लिपि', '##मा', 'आधारित', 'एक', '##प्रा', '##चीन', 'ब्राह्', '##मी', 'लिपि', '##हो', '।', 'यसको', 'प्रयोग', '##भार', '##तीय', 'उपमहा', '##द्वी', '##पमा', 'हुने', 'गर्दछ', '।', 'यसको', '[SEP]'], ['[CLS]', 'ि', '##बा', '##याँ', 'देखि', 'दायाँ', 'सम्म', 'लेख', '##िने', '##अ', '##क्षर', '##ात्मक', 'लिपि', '##मा', 'आधारित', 'एक', '##प्रा', '##चीन', 'ब्राह्', '##मी', 'लिपि', '##हो', '।', 'यसको', 'प्रयोग', '##भार', '##तीय', 'उपमहा', '##द्वी', '##पमा', 'हुने', 'गर्दछ', '।', 'यसको', 'विकास', '##प्रा', '##चीन', 'भारतमा', 'पहिलो', 'देखि', 'चौथो', 'शताब्दीको', 'बीचमा', 'भएको', 'थियो', 'भने', 'यसको', 'प्रयोग', 'सातौँ', 'शताब्दी', 'देखी', 'हुँदै', 'आएको', 'छ', '।', 'देव', '##नागर', '##ी', 'लिपि', '##मा', ',', '[SEP]'], ['[CLS]', 'विकास', '##प्रा', '##चीन', 'भारतमा', 'पहिलो', 'देखि', 'चौथो', 'शताब्दीको', 'बीचमा', 'भएको', 'थियो', 'भने', 'यसको', 'प्रयोग', 'सातौँ', 'शताब्दी', 'देखी', 'हुँदै', 'आएको', 'छ', '।', 'देव', '##नागर', '##ी', 'लिपि', '##मा', ',', '[SEP]'], ['[CLS]', 'विकास', '##प्रा', '##चीन', 'भारतमा', 'पहिलो', 'देखि', 'चौथो', 'शताब्दीको', 'बीचमा', 'भएको', 'थियो', 'भने', 'यसको', 'प्रयोग', 'सातौँ', 'शताब्दी', 'देखी', 'हुँदै', 'आएको', 'छ', '।', 'देव', '##नागर', '##ी', 'लिपि', '##मा', ',', '४७', 'वटा', '##वर', '##्', '##ण', '##हरू', 'हुन्छन्', 'जसमा', '१४', 'वटा', '##स्वर', '##वर', '##्', '##ण', '##र', '३३', 'वटा', '##व्य', '##ञ्जन', '##वर', '##्', '##ण', '##हुन्छ', '##न्', '।', 'यो', 'संसारमा', 'सबैभन्दा', 'बढी', 'प्रयोग', 'हुने', 'लिपि', 'मध्ये', 'चौथो', 'हो', 'ज', '##हा', '[SEP]']]\n"
     ]
    }
   ],
   "source": [
    "print(\"SentencePiece Tokenized IDs:\", input_ids_sp[:5])\n",
    "print(\"SentencePiece Tokens:\", tokens_sp[:5])\n",
    "print(\"WordPiece Tokenized IDs:\", input_ids_wp[:5])\n",
    "print(\"WordPiece Tokens:\", tokens_wp[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Define Metrics for Evaluation\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = logits.argmax(axis=-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_transformer_model(dataset, tokenizer, model_name=\"xlm-roberta-base\", num_labels=2):\n",
    "    \"\"\"\n",
    "    Fine-tune a transformer-based model for Nepali text classification.\n",
    "    \"\"\"\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./results\",\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=16,\n",
    "        num_train_epochs=3,\n",
    "        weight_decay=0.01,\n",
    "        save_strategy=\"epoch\",\n",
    "        logging_dir=\"./logs\",\n",
    "    )\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=dataset[\"train\"],\n",
    "        eval_dataset=dataset[\"test\"],\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "    trainer.train()\n",
    "    print(\"Training complete!\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nepali_tokenizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run the pipeline\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnepali_tokenizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NepaliTokenizer\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# File paths\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     nepali_text_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/L E G I O N/Desktop/Nepali-LLM/data/merged_nepali_corpus.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Path to a file with Nepali sentences\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'nepali_tokenizer'"
     ]
    }
   ],
   "source": [
    "# Run the pipeline\n",
    "from nepali_tokenizer import NepaliTokenizer\n",
    "if __name__ == \"__main__\":\n",
    "    # File paths\n",
    "    nepali_text_file = \"C:/Users/L E G I O N/Desktop/Nepali-LLM/data/merged_nepali_corpus.txt\"  # Path to a file with Nepali sentences\n",
    "    spm_model_prefix = \"nepali_spm\"\n",
    "\n",
    "    # Train SentencePiece Tokenizer\n",
    "    train_sentencepiece_tokenizer(nepali_text_file, spm_model_prefix)\n",
    "\n",
    "    # Load Dataset\n",
    "    dataset = load_nepali_dataset()\n",
    "\n",
    "    # Tokenize Dataset\n",
    "  \n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "# Initialize the NepaliTokenizer\n",
    "tokenizer = NepaliTokenizer()\n",
    "\n",
    "# Function to load Nepali sentences from a .txt file\n",
    "def load_nepali_text_file(nepali_text_file):\n",
    "    \"\"\"\n",
    "    Load Nepali text from a .txt file and return a list of sentences.\n",
    "    \"\"\"\n",
    "    with open(nepali_text_file, 'r', encoding='utf-8') as f:\n",
    "        # Read all lines from the file\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    # Clean up the lines: Remove any unnecessary newlines and empty lines\n",
    "    sentences = [line.strip() for line in lines if line.strip()]\n",
    "    return sentences\n",
    "\n",
    "# Function to tokenize the dataset using NepaliTokenizer\n",
    "def tokenize_dataset(sentences):\n",
    "    \"\"\"\n",
    "    Tokenizes each Nepali sentence using NepaliTokenizer.\n",
    "    \"\"\"\n",
    "    def tokenize_fn(text):\n",
    "        # Tokenizing the text using NepaliTokenizer\n",
    "        return tokenizer.tokenizer(text)\n",
    "    \n",
    "    # Tokenizing each sentence\n",
    "    tokenized_sentences = [tokenize_fn(sentence) for sentence in sentences]\n",
    "    \n",
    "    return tokenized_sentences\n",
    "\n",
    "# Load Nepali text from your local .txt file\n",
    "\n",
    "sentences = load_nepali_text_file(nepali_text_file)\n",
    "\n",
    "# Tokenize the sentences using NepaliTokenizer\n",
    "tokenized_sentences = tokenize_dataset(sentences)\n",
    "\n",
    "# Convert the tokenized data into a Hugging Face Dataset format\n",
    "dataset = Dataset.from_dict({\"text\": sentences, \"input_ids\": tokenized_sentences})\n",
    "\n",
    "# Optionally, display the first few entries of the dataset\n",
    "print(dataset[:5])  # Print first 5 tokenized entries\n",
    "\n",
    "#     # # Train Transformer Model\n",
    "# trained_model = train_transformer_model(dataset, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data type: <class 'dict'>\n",
      "Dictionary with keys: ['input_ids', 'tokens']\n",
      "'train' key contains 77044 sequences. First sequence:\n",
      "[1, 8452, 8472, 10744, 8445, 10488, 8334, 5748, 9313, 13033, 5713, 15959, 8340, 14427, 8444, 11867, 1496, 8691, 13459, 10683, 5792, 5796, 16, 11341, 5723, 8892, 8429, 13816, 9802, 8371, 8425, 1496, 10072, 25694, 5712, 20967, 5757, 5763, 10478, 15925, 5712, 20967, 8392, 8585, 9267, 17488, 9279, 8892, 8492, 5757, 11339, 19392, 20967, 8337, 12152, 8472, 13896, 15893, 21336, 9148, 20967, 9313, 1496, 9640, 9074, 12487, 11450, 28511, 28072, 11098, 8511, 11322, 1496, 9640, 2]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Path to your .pkl file\n",
    "file_path = 'C:/Users/L E G I O N/Desktop/Nepali-LLM/Preprocessing/wordpiece_tokenized.pkl'\n",
    "\n",
    "# Open and load the file\n",
    "with open(file_path, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# Print the type of the loaded object\n",
    "print(f\"Loaded data type: {type(data)}\")\n",
    "\n",
    "# Inspect the data\n",
    "if isinstance(data, list):\n",
    "    print(f\"List with {len(data)} elements. First element:\")\n",
    "    print(data[0])\n",
    "elif isinstance(data, dict):\n",
    "    print(f\"Dictionary with keys: {list(data.keys())}\")\n",
    "    # Example: Inspect the 'train' key if it exists\n",
    "    if 'input_ids' in data:\n",
    "        print(f\"'train' key contains {len(data['input_ids'])} sequences. First sequence:\")\n",
    "        print(data['input_ids'][0])\n",
    "else:\n",
    "    print(\"Loaded data:\")\n",
    "    print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 30522\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 74, 30522])\n",
      "Targets shape: torch.Size([32, 74])\n",
      "Reshaped Outputs shape: torch.Size([2368, 30522])\n",
      "Reshaped Targets shape: torch.Size([2368])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 93, 30522])\n",
      "Targets shape: torch.Size([32, 93])\n",
      "Reshaped Outputs shape: torch.Size([2976, 30522])\n",
      "Reshaped Targets shape: torch.Size([2976])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 71, 30522])\n",
      "Targets shape: torch.Size([32, 71])\n",
      "Reshaped Outputs shape: torch.Size([2272, 30522])\n",
      "Reshaped Targets shape: torch.Size([2272])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 79, 30522])\n",
      "Targets shape: torch.Size([32, 79])\n",
      "Reshaped Outputs shape: torch.Size([2528, 30522])\n",
      "Reshaped Targets shape: torch.Size([2528])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 78, 30522])\n",
      "Targets shape: torch.Size([32, 78])\n",
      "Reshaped Outputs shape: torch.Size([2496, 30522])\n",
      "Reshaped Targets shape: torch.Size([2496])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 72, 30522])\n",
      "Targets shape: torch.Size([32, 72])\n",
      "Reshaped Outputs shape: torch.Size([2304, 30522])\n",
      "Reshaped Targets shape: torch.Size([2304])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 78, 30522])\n",
      "Targets shape: torch.Size([32, 78])\n",
      "Reshaped Outputs shape: torch.Size([2496, 30522])\n",
      "Reshaped Targets shape: torch.Size([2496])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 66, 30522])\n",
      "Targets shape: torch.Size([32, 66])\n",
      "Reshaped Outputs shape: torch.Size([2112, 30522])\n",
      "Reshaped Targets shape: torch.Size([2112])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 75, 30522])\n",
      "Targets shape: torch.Size([32, 75])\n",
      "Reshaped Outputs shape: torch.Size([2400, 30522])\n",
      "Reshaped Targets shape: torch.Size([2400])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 69, 30522])\n",
      "Targets shape: torch.Size([32, 69])\n",
      "Reshaped Outputs shape: torch.Size([2208, 30522])\n",
      "Reshaped Targets shape: torch.Size([2208])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 71, 30522])\n",
      "Targets shape: torch.Size([32, 71])\n",
      "Reshaped Outputs shape: torch.Size([2272, 30522])\n",
      "Reshaped Targets shape: torch.Size([2272])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 80, 30522])\n",
      "Targets shape: torch.Size([32, 80])\n",
      "Reshaped Outputs shape: torch.Size([2560, 30522])\n",
      "Reshaped Targets shape: torch.Size([2560])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 64, 30522])\n",
      "Targets shape: torch.Size([32, 64])\n",
      "Reshaped Outputs shape: torch.Size([2048, 30522])\n",
      "Reshaped Targets shape: torch.Size([2048])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 76, 30522])\n",
      "Targets shape: torch.Size([32, 76])\n",
      "Reshaped Outputs shape: torch.Size([2432, 30522])\n",
      "Reshaped Targets shape: torch.Size([2432])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 78, 30522])\n",
      "Targets shape: torch.Size([32, 78])\n",
      "Reshaped Outputs shape: torch.Size([2496, 30522])\n",
      "Reshaped Targets shape: torch.Size([2496])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 62, 30522])\n",
      "Targets shape: torch.Size([32, 62])\n",
      "Reshaped Outputs shape: torch.Size([1984, 30522])\n",
      "Reshaped Targets shape: torch.Size([1984])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 82, 30522])\n",
      "Targets shape: torch.Size([32, 82])\n",
      "Reshaped Outputs shape: torch.Size([2624, 30522])\n",
      "Reshaped Targets shape: torch.Size([2624])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 79, 30522])\n",
      "Targets shape: torch.Size([32, 79])\n",
      "Reshaped Outputs shape: torch.Size([2528, 30522])\n",
      "Reshaped Targets shape: torch.Size([2528])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 64, 30522])\n",
      "Targets shape: torch.Size([32, 64])\n",
      "Reshaped Outputs shape: torch.Size([2048, 30522])\n",
      "Reshaped Targets shape: torch.Size([2048])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 61, 30522])\n",
      "Targets shape: torch.Size([32, 61])\n",
      "Reshaped Outputs shape: torch.Size([1952, 30522])\n",
      "Reshaped Targets shape: torch.Size([1952])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 89, 30522])\n",
      "Targets shape: torch.Size([32, 89])\n",
      "Reshaped Outputs shape: torch.Size([2848, 30522])\n",
      "Reshaped Targets shape: torch.Size([2848])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 66, 30522])\n",
      "Targets shape: torch.Size([32, 66])\n",
      "Reshaped Outputs shape: torch.Size([2112, 30522])\n",
      "Reshaped Targets shape: torch.Size([2112])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 71, 30522])\n",
      "Targets shape: torch.Size([32, 71])\n",
      "Reshaped Outputs shape: torch.Size([2272, 30522])\n",
      "Reshaped Targets shape: torch.Size([2272])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 72, 30522])\n",
      "Targets shape: torch.Size([32, 72])\n",
      "Reshaped Outputs shape: torch.Size([2304, 30522])\n",
      "Reshaped Targets shape: torch.Size([2304])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 87, 30522])\n",
      "Targets shape: torch.Size([32, 87])\n",
      "Reshaped Outputs shape: torch.Size([2784, 30522])\n",
      "Reshaped Targets shape: torch.Size([2784])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 80, 30522])\n",
      "Targets shape: torch.Size([32, 80])\n",
      "Reshaped Outputs shape: torch.Size([2560, 30522])\n",
      "Reshaped Targets shape: torch.Size([2560])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 86, 30522])\n",
      "Targets shape: torch.Size([32, 86])\n",
      "Reshaped Outputs shape: torch.Size([2752, 30522])\n",
      "Reshaped Targets shape: torch.Size([2752])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 64, 30522])\n",
      "Targets shape: torch.Size([32, 64])\n",
      "Reshaped Outputs shape: torch.Size([2048, 30522])\n",
      "Reshaped Targets shape: torch.Size([2048])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 60, 30522])\n",
      "Targets shape: torch.Size([32, 60])\n",
      "Reshaped Outputs shape: torch.Size([1920, 30522])\n",
      "Reshaped Targets shape: torch.Size([1920])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 78, 30522])\n",
      "Targets shape: torch.Size([32, 78])\n",
      "Reshaped Outputs shape: torch.Size([2496, 30522])\n",
      "Reshaped Targets shape: torch.Size([2496])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 69, 30522])\n",
      "Targets shape: torch.Size([32, 69])\n",
      "Reshaped Outputs shape: torch.Size([2208, 30522])\n",
      "Reshaped Targets shape: torch.Size([2208])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 75, 30522])\n",
      "Targets shape: torch.Size([32, 75])\n",
      "Reshaped Outputs shape: torch.Size([2400, 30522])\n",
      "Reshaped Targets shape: torch.Size([2400])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 100, 30522])\n",
      "Targets shape: torch.Size([32, 100])\n",
      "Reshaped Outputs shape: torch.Size([3200, 30522])\n",
      "Reshaped Targets shape: torch.Size([3200])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 67, 30522])\n",
      "Targets shape: torch.Size([32, 67])\n",
      "Reshaped Outputs shape: torch.Size([2144, 30522])\n",
      "Reshaped Targets shape: torch.Size([2144])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 76, 30522])\n",
      "Targets shape: torch.Size([32, 76])\n",
      "Reshaped Outputs shape: torch.Size([2432, 30522])\n",
      "Reshaped Targets shape: torch.Size([2432])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 71, 30522])\n",
      "Targets shape: torch.Size([32, 71])\n",
      "Reshaped Outputs shape: torch.Size([2272, 30522])\n",
      "Reshaped Targets shape: torch.Size([2272])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 78, 30522])\n",
      "Targets shape: torch.Size([32, 78])\n",
      "Reshaped Outputs shape: torch.Size([2496, 30522])\n",
      "Reshaped Targets shape: torch.Size([2496])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 76, 30522])\n",
      "Targets shape: torch.Size([32, 76])\n",
      "Reshaped Outputs shape: torch.Size([2432, 30522])\n",
      "Reshaped Targets shape: torch.Size([2432])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 64, 30522])\n",
      "Targets shape: torch.Size([32, 64])\n",
      "Reshaped Outputs shape: torch.Size([2048, 30522])\n",
      "Reshaped Targets shape: torch.Size([2048])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 68, 30522])\n",
      "Targets shape: torch.Size([32, 68])\n",
      "Reshaped Outputs shape: torch.Size([2176, 30522])\n",
      "Reshaped Targets shape: torch.Size([2176])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 65, 30522])\n",
      "Targets shape: torch.Size([32, 65])\n",
      "Reshaped Outputs shape: torch.Size([2080, 30522])\n",
      "Reshaped Targets shape: torch.Size([2080])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 78, 30522])\n",
      "Targets shape: torch.Size([32, 78])\n",
      "Reshaped Outputs shape: torch.Size([2496, 30522])\n",
      "Reshaped Targets shape: torch.Size([2496])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 74, 30522])\n",
      "Targets shape: torch.Size([32, 74])\n",
      "Reshaped Outputs shape: torch.Size([2368, 30522])\n",
      "Reshaped Targets shape: torch.Size([2368])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 63, 30522])\n",
      "Targets shape: torch.Size([32, 63])\n",
      "Reshaped Outputs shape: torch.Size([2016, 30522])\n",
      "Reshaped Targets shape: torch.Size([2016])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 70, 30522])\n",
      "Targets shape: torch.Size([32, 70])\n",
      "Reshaped Outputs shape: torch.Size([2240, 30522])\n",
      "Reshaped Targets shape: torch.Size([2240])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 112, 30522])\n",
      "Targets shape: torch.Size([32, 112])\n",
      "Reshaped Outputs shape: torch.Size([3584, 30522])\n",
      "Reshaped Targets shape: torch.Size([3584])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 69, 30522])\n",
      "Targets shape: torch.Size([32, 69])\n",
      "Reshaped Outputs shape: torch.Size([2208, 30522])\n",
      "Reshaped Targets shape: torch.Size([2208])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 57, 30522])\n",
      "Targets shape: torch.Size([32, 57])\n",
      "Reshaped Outputs shape: torch.Size([1824, 30522])\n",
      "Reshaped Targets shape: torch.Size([1824])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 57, 30522])\n",
      "Targets shape: torch.Size([32, 57])\n",
      "Reshaped Outputs shape: torch.Size([1824, 30522])\n",
      "Reshaped Targets shape: torch.Size([1824])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 58, 30522])\n",
      "Targets shape: torch.Size([32, 58])\n",
      "Reshaped Outputs shape: torch.Size([1856, 30522])\n",
      "Reshaped Targets shape: torch.Size([1856])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 70, 30522])\n",
      "Targets shape: torch.Size([32, 70])\n",
      "Reshaped Outputs shape: torch.Size([2240, 30522])\n",
      "Reshaped Targets shape: torch.Size([2240])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 71, 30522])\n",
      "Targets shape: torch.Size([32, 71])\n",
      "Reshaped Outputs shape: torch.Size([2272, 30522])\n",
      "Reshaped Targets shape: torch.Size([2272])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 71, 30522])\n",
      "Targets shape: torch.Size([32, 71])\n",
      "Reshaped Outputs shape: torch.Size([2272, 30522])\n",
      "Reshaped Targets shape: torch.Size([2272])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 66, 30522])\n",
      "Targets shape: torch.Size([32, 66])\n",
      "Reshaped Outputs shape: torch.Size([2112, 30522])\n",
      "Reshaped Targets shape: torch.Size([2112])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 75, 30522])\n",
      "Targets shape: torch.Size([32, 75])\n",
      "Reshaped Outputs shape: torch.Size([2400, 30522])\n",
      "Reshaped Targets shape: torch.Size([2400])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 97, 30522])\n",
      "Targets shape: torch.Size([32, 97])\n",
      "Reshaped Outputs shape: torch.Size([3104, 30522])\n",
      "Reshaped Targets shape: torch.Size([3104])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 72, 30522])\n",
      "Targets shape: torch.Size([32, 72])\n",
      "Reshaped Outputs shape: torch.Size([2304, 30522])\n",
      "Reshaped Targets shape: torch.Size([2304])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 80, 30522])\n",
      "Targets shape: torch.Size([32, 80])\n",
      "Reshaped Outputs shape: torch.Size([2560, 30522])\n",
      "Reshaped Targets shape: torch.Size([2560])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 79, 30522])\n",
      "Targets shape: torch.Size([32, 79])\n",
      "Reshaped Outputs shape: torch.Size([2528, 30522])\n",
      "Reshaped Targets shape: torch.Size([2528])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 87, 30522])\n",
      "Targets shape: torch.Size([32, 87])\n",
      "Reshaped Outputs shape: torch.Size([2784, 30522])\n",
      "Reshaped Targets shape: torch.Size([2784])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 78, 30522])\n",
      "Targets shape: torch.Size([32, 78])\n",
      "Reshaped Outputs shape: torch.Size([2496, 30522])\n",
      "Reshaped Targets shape: torch.Size([2496])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 68, 30522])\n",
      "Targets shape: torch.Size([32, 68])\n",
      "Reshaped Outputs shape: torch.Size([2176, 30522])\n",
      "Reshaped Targets shape: torch.Size([2176])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 73, 30522])\n",
      "Targets shape: torch.Size([32, 73])\n",
      "Reshaped Outputs shape: torch.Size([2336, 30522])\n",
      "Reshaped Targets shape: torch.Size([2336])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 68, 30522])\n",
      "Targets shape: torch.Size([32, 68])\n",
      "Reshaped Outputs shape: torch.Size([2176, 30522])\n",
      "Reshaped Targets shape: torch.Size([2176])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 89, 30522])\n",
      "Targets shape: torch.Size([32, 89])\n",
      "Reshaped Outputs shape: torch.Size([2848, 30522])\n",
      "Reshaped Targets shape: torch.Size([2848])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 93, 30522])\n",
      "Targets shape: torch.Size([32, 93])\n",
      "Reshaped Outputs shape: torch.Size([2976, 30522])\n",
      "Reshaped Targets shape: torch.Size([2976])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 71, 30522])\n",
      "Targets shape: torch.Size([32, 71])\n",
      "Reshaped Outputs shape: torch.Size([2272, 30522])\n",
      "Reshaped Targets shape: torch.Size([2272])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 86, 30522])\n",
      "Targets shape: torch.Size([32, 86])\n",
      "Reshaped Outputs shape: torch.Size([2752, 30522])\n",
      "Reshaped Targets shape: torch.Size([2752])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 81, 30522])\n",
      "Targets shape: torch.Size([32, 81])\n",
      "Reshaped Outputs shape: torch.Size([2592, 30522])\n",
      "Reshaped Targets shape: torch.Size([2592])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 88, 30522])\n",
      "Targets shape: torch.Size([32, 88])\n",
      "Reshaped Outputs shape: torch.Size([2816, 30522])\n",
      "Reshaped Targets shape: torch.Size([2816])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 64, 30522])\n",
      "Targets shape: torch.Size([32, 64])\n",
      "Reshaped Outputs shape: torch.Size([2048, 30522])\n",
      "Reshaped Targets shape: torch.Size([2048])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 64, 30522])\n",
      "Targets shape: torch.Size([32, 64])\n",
      "Reshaped Outputs shape: torch.Size([2048, 30522])\n",
      "Reshaped Targets shape: torch.Size([2048])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 61, 30522])\n",
      "Targets shape: torch.Size([32, 61])\n",
      "Reshaped Outputs shape: torch.Size([1952, 30522])\n",
      "Reshaped Targets shape: torch.Size([1952])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 68, 30522])\n",
      "Targets shape: torch.Size([32, 68])\n",
      "Reshaped Outputs shape: torch.Size([2176, 30522])\n",
      "Reshaped Targets shape: torch.Size([2176])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 70, 30522])\n",
      "Targets shape: torch.Size([32, 70])\n",
      "Reshaped Outputs shape: torch.Size([2240, 30522])\n",
      "Reshaped Targets shape: torch.Size([2240])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 84, 30522])\n",
      "Targets shape: torch.Size([32, 84])\n",
      "Reshaped Outputs shape: torch.Size([2688, 30522])\n",
      "Reshaped Targets shape: torch.Size([2688])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 66, 30522])\n",
      "Targets shape: torch.Size([32, 66])\n",
      "Reshaped Outputs shape: torch.Size([2112, 30522])\n",
      "Reshaped Targets shape: torch.Size([2112])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 73, 30522])\n",
      "Targets shape: torch.Size([32, 73])\n",
      "Reshaped Outputs shape: torch.Size([2336, 30522])\n",
      "Reshaped Targets shape: torch.Size([2336])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 76, 30522])\n",
      "Targets shape: torch.Size([32, 76])\n",
      "Reshaped Outputs shape: torch.Size([2432, 30522])\n",
      "Reshaped Targets shape: torch.Size([2432])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 81, 30522])\n",
      "Targets shape: torch.Size([32, 81])\n",
      "Reshaped Outputs shape: torch.Size([2592, 30522])\n",
      "Reshaped Targets shape: torch.Size([2592])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 75, 30522])\n",
      "Targets shape: torch.Size([32, 75])\n",
      "Reshaped Outputs shape: torch.Size([2400, 30522])\n",
      "Reshaped Targets shape: torch.Size([2400])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 70, 30522])\n",
      "Targets shape: torch.Size([32, 70])\n",
      "Reshaped Outputs shape: torch.Size([2240, 30522])\n",
      "Reshaped Targets shape: torch.Size([2240])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 81, 30522])\n",
      "Targets shape: torch.Size([32, 81])\n",
      "Reshaped Outputs shape: torch.Size([2592, 30522])\n",
      "Reshaped Targets shape: torch.Size([2592])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 72, 30522])\n",
      "Targets shape: torch.Size([32, 72])\n",
      "Reshaped Outputs shape: torch.Size([2304, 30522])\n",
      "Reshaped Targets shape: torch.Size([2304])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 74, 30522])\n",
      "Targets shape: torch.Size([32, 74])\n",
      "Reshaped Outputs shape: torch.Size([2368, 30522])\n",
      "Reshaped Targets shape: torch.Size([2368])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 74, 30522])\n",
      "Targets shape: torch.Size([32, 74])\n",
      "Reshaped Outputs shape: torch.Size([2368, 30522])\n",
      "Reshaped Targets shape: torch.Size([2368])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 71, 30522])\n",
      "Targets shape: torch.Size([32, 71])\n",
      "Reshaped Outputs shape: torch.Size([2272, 30522])\n",
      "Reshaped Targets shape: torch.Size([2272])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 75, 30522])\n",
      "Targets shape: torch.Size([32, 75])\n",
      "Reshaped Outputs shape: torch.Size([2400, 30522])\n",
      "Reshaped Targets shape: torch.Size([2400])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 66, 30522])\n",
      "Targets shape: torch.Size([32, 66])\n",
      "Reshaped Outputs shape: torch.Size([2112, 30522])\n",
      "Reshaped Targets shape: torch.Size([2112])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 61, 30522])\n",
      "Targets shape: torch.Size([32, 61])\n",
      "Reshaped Outputs shape: torch.Size([1952, 30522])\n",
      "Reshaped Targets shape: torch.Size([1952])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 63, 30522])\n",
      "Targets shape: torch.Size([32, 63])\n",
      "Reshaped Outputs shape: torch.Size([2016, 30522])\n",
      "Reshaped Targets shape: torch.Size([2016])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 66, 30522])\n",
      "Targets shape: torch.Size([32, 66])\n",
      "Reshaped Outputs shape: torch.Size([2112, 30522])\n",
      "Reshaped Targets shape: torch.Size([2112])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 63, 30522])\n",
      "Targets shape: torch.Size([32, 63])\n",
      "Reshaped Outputs shape: torch.Size([2016, 30522])\n",
      "Reshaped Targets shape: torch.Size([2016])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 63, 30522])\n",
      "Targets shape: torch.Size([32, 63])\n",
      "Reshaped Outputs shape: torch.Size([2016, 30522])\n",
      "Reshaped Targets shape: torch.Size([2016])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 73, 30522])\n",
      "Targets shape: torch.Size([32, 73])\n",
      "Reshaped Outputs shape: torch.Size([2336, 30522])\n",
      "Reshaped Targets shape: torch.Size([2336])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 58, 30522])\n",
      "Targets shape: torch.Size([32, 58])\n",
      "Reshaped Outputs shape: torch.Size([1856, 30522])\n",
      "Reshaped Targets shape: torch.Size([1856])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 58, 30522])\n",
      "Targets shape: torch.Size([32, 58])\n",
      "Reshaped Outputs shape: torch.Size([1856, 30522])\n",
      "Reshaped Targets shape: torch.Size([1856])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 66, 30522])\n",
      "Targets shape: torch.Size([32, 66])\n",
      "Reshaped Outputs shape: torch.Size([2112, 30522])\n",
      "Reshaped Targets shape: torch.Size([2112])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 66, 30522])\n",
      "Targets shape: torch.Size([32, 66])\n",
      "Reshaped Outputs shape: torch.Size([2112, 30522])\n",
      "Reshaped Targets shape: torch.Size([2112])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 58, 30522])\n",
      "Targets shape: torch.Size([32, 58])\n",
      "Reshaped Outputs shape: torch.Size([1856, 30522])\n",
      "Reshaped Targets shape: torch.Size([1856])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 57, 30522])\n",
      "Targets shape: torch.Size([32, 57])\n",
      "Reshaped Outputs shape: torch.Size([1824, 30522])\n",
      "Reshaped Targets shape: torch.Size([1824])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 56, 30522])\n",
      "Targets shape: torch.Size([32, 56])\n",
      "Reshaped Outputs shape: torch.Size([1792, 30522])\n",
      "Reshaped Targets shape: torch.Size([1792])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 59, 30522])\n",
      "Targets shape: torch.Size([32, 59])\n",
      "Reshaped Outputs shape: torch.Size([1888, 30522])\n",
      "Reshaped Targets shape: torch.Size([1888])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 59, 30522])\n",
      "Targets shape: torch.Size([32, 59])\n",
      "Reshaped Outputs shape: torch.Size([1888, 30522])\n",
      "Reshaped Targets shape: torch.Size([1888])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 56, 30522])\n",
      "Targets shape: torch.Size([32, 56])\n",
      "Reshaped Outputs shape: torch.Size([1792, 30522])\n",
      "Reshaped Targets shape: torch.Size([1792])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 54, 30522])\n",
      "Targets shape: torch.Size([32, 54])\n",
      "Reshaped Outputs shape: torch.Size([1728, 30522])\n",
      "Reshaped Targets shape: torch.Size([1728])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 56, 30522])\n",
      "Targets shape: torch.Size([32, 56])\n",
      "Reshaped Outputs shape: torch.Size([1792, 30522])\n",
      "Reshaped Targets shape: torch.Size([1792])\n",
      "Epoch 1, Batch shape debug:\n",
      "Outputs shape: torch.Size([32, 54, 30522])\n",
      "Targets shape: torch.Size([32, 54])\n",
      "Reshaped Outputs shape: torch.Size([1728, 30522])\n",
      "Reshaped Targets shape: torch.Size([1728])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pickle\n",
    "import numpy as np\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# Enable anomaly detection for debugging in-place errors\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "# Load tokenized data and Word2Vec embeddings\n",
    "with open('wordpiece_tokenized.pkl', 'rb') as f:\n",
    "    tokenized_data = pickle.load(f)\n",
    "\n",
    "# Ensure that we have 'input_ids' and 'tokens' in the data\n",
    "input_ids = tokenized_data.get('input_ids', [])\n",
    "tokens = tokenized_data.get('tokens', [])\n",
    "\n",
    "if not input_ids or not tokens:\n",
    "    raise ValueError(\"The tokenized data does not contain 'input_ids' or 'tokens'.\")\n",
    "\n",
    "# Load Word2Vec embeddings\n",
    "word2vec_path = \"processed_normalized.word2vec.wv.vectors.npy\"\n",
    "word2vec = np.load(word2vec_path)\n",
    "\n",
    "# Create embedding matrix\n",
    "vocab_file = 'wordpiece_vocab.vocab'\n",
    "\n",
    "# Read the vocabulary file and create a mapping\n",
    "vocab = {}\n",
    "idx_to_word = {}\n",
    "with open(vocab_file, 'r', encoding='utf-8') as f:\n",
    "    for idx, line in enumerate(f):\n",
    "        token = line.strip()  # Remove any extra whitespace\n",
    "        vocab[token] = idx\n",
    "        idx_to_word[idx] = token\n",
    "\n",
    "# Get the vocabulary size\n",
    "vocab_size = len(vocab)\n",
    "print(f\"Vocabulary Size: {vocab_size}\")\n",
    "\n",
    "embedding_dim = word2vec.shape[1]\n",
    "embedding_matrix = torch.tensor(word2vec, dtype=torch.float32)\n",
    "\n",
    "# Model: Simple RNN-based Language Model\n",
    "class SmallTextGenerator(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers):\n",
    "        super(SmallTextGenerator, self).__init__()\n",
    "        self.embedding = nn.Embedding.from_pretrained(embedding_matrix, freeze=False)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        embeds = self.embedding(x)\n",
    "        output, hidden = self.rnn(embeds, hidden)\n",
    "        logits = self.fc(output)\n",
    "        return logits, hidden\n",
    "\n",
    "# Hyperparameters\n",
    "hidden_dim = 128\n",
    "num_layers = 2\n",
    "learning_rate = 0.001\n",
    "batch_size = 32\n",
    "num_epochs = 10\n",
    "\n",
    "# Initialize model, loss, and optimizer\n",
    "model = SmallTextGenerator(vocab_size, embedding_dim, hidden_dim, num_layers)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Prepare data for training\n",
    "def get_batches(data, batch_size):\n",
    "    for i in range(0, len(data) - batch_size + 1, batch_size):\n",
    "        batch = data[i:i+batch_size]\n",
    "        # Pad sequences to the same length within a batch\n",
    "        padded_batch = pad_sequence([torch.tensor(seq, dtype=torch.long) for seq in batch], batch_first=True)\n",
    "        yield padded_batch\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    hidden = None\n",
    "    for batch in get_batches(input_ids, batch_size):\n",
    "        inputs = batch[:, :-1]  # All but the last token\n",
    "        targets = batch[:, 1:]  # All but the first token\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs, hidden = model(inputs, hidden)\n",
    "\n",
    "        # Print the shape of outputs and targets for debugging\n",
    "        print(f\"Epoch {epoch+1}, Batch shape debug:\")\n",
    "        print(f\"Outputs shape: {outputs.shape}\")\n",
    "        print(f\"Targets shape: {targets.shape}\")\n",
    "\n",
    "        # Reshape the outputs and targets to 1D for CrossEntropyLoss\n",
    "        outputs_reshaped = outputs.contiguous().view(-1, vocab_size)\n",
    "        targets_reshaped = targets.contiguous().view(-1)\n",
    "\n",
    "        # Check the reshaped shapes\n",
    "        print(f\"Reshaped Outputs shape: {outputs_reshaped.shape}\")\n",
    "        print(f\"Reshaped Targets shape: {targets_reshaped.shape}\")\n",
    "\n",
    "        # Ensure the reshaped tensors match\n",
    "        assert outputs_reshaped.size(0) == targets_reshaped.size(0), \"Shape mismatch between outputs and targets.\"\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs_reshaped, targets_reshaped)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()  # Removed retain_graph=True\n",
    "        optimizer.step()\n",
    "\n",
    "        # Clear hidden states to avoid holding the computational graph\n",
    "        hidden = None\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "# Text generation function\n",
    "def generate_text(model, start_token, max_length=50, temperature=1.0):\n",
    "    model.eval()\n",
    "    generated = [start_token]\n",
    "    input_token = torch.tensor([start_token], dtype=torch.long).unsqueeze(0)\n",
    "    hidden = None\n",
    "\n",
    "    for _ in range(max_length):\n",
    "        output, hidden = model(input_token, hidden)\n",
    "        output = output.squeeze(0).div(temperature).exp()\n",
    "        next_token = torch.multinomial(output, num_samples=1).item()\n",
    "        generated.append(next_token)\n",
    "        input_token = torch.tensor([[next_token]], dtype=torch.long)\n",
    "\n",
    "        if next_token == vocab.get('<EOS>', -1):  # Check for EOS token\n",
    "            break\n",
    "\n",
    "    return ' '.join([idx_to_word.get(idx, \"<UNK>\") for idx in generated])\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"small_nepali_text_generator.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
